<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jiang Liu</title>

    <meta name="author" content="Jiang Liu">
    <meta name="description" content="I am a PhD student at Cardiff University, UK.">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="images/seal_icon.png">
    <link href="https://fonts.googleapis.com/css?family=Cinzel:400,700,900&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Cormorant+Infant:wght@500&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Bellefair&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Rock+Salt&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Cormorant+SC:wght@300;400;500;600;700&display=swap"
          rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Montez&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="fontawesome/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Jiang Liu</name>
                        <hr>
                        </p>
                        <p style="text-align:left">
                            <tldr>I am a PhD student (2022 - now) in the <a href="https://www.cardiff.ac.uk/research/explore/research-units/multimedia-computing">Human-Centric Machine Vision and Intelligence Group</a> within the <a href="https://www.cardiff.ac.uk/computer-science">School of Computer Science and Informatics, Cardiff University, UK</a>, advised by <a href="https://profiles.cardiff.ac.uk/staff/liuh35">Prof. Hantao Liu </a> and <a href="https://profiles.cardiff.ac.uk/staff/stawarzk">Dr. Katarzyna Stawarz</a>. <br><br>

Before that, I obtained my M.S. and B.S. degrees from the School of Information and Control Engineering at China University of Mining and Technology in 2022 and 2019, respectively, advised by <a href="https://faculty.cumt.edu.cn/LSY/zh_CN/index.htm">Prof. Shiyin Li</a> and <a href="https://ins.seu.edu.cn/yy/list.htm">Dr. Yuan Yang</a>. I used to be a visiting student at Arizona State University (2019) and a research assistant at Southeast University (2020). <br><br>


                                My research interests primarily lie in <strong>image quality assessment</strong>, <strong>action quality assessment</strong> and <strong>saliency prediction</strong>. I also have a research background in smart buildings and wireless sensing. 
                            </tldr>
                        </p>
                        <p style="text-align:center">
                            <a href="mailto:liuj137@cardiff.ac.uk"><i class="fa fa-envelope fa-2x"></i></a> &nbsp
                            &nbsp &nbsp &nbsp &nbsp
                            <a href="data/CV.pdf">CV</a> &nbsp
                            &nbsp &nbsp &nbsp &nbsp

                            <a href="https://scholar.google.co.uk/citations?user=ZSplXPEAAAAJ&hl=en"><i
                                    class="ai ai-google-scholar ai-2x"></i></a> &nbsp &nbsp &nbsp &nbsp &nbsp
                            <a href="https://github.com/jiangliu5"><i class="fab fa-github fa-2x"></i></a>

			    &nbsp &nbsp &nbsp &nbsp &nbsp <a href="https://orcid.org/0000-0002-8879-5375">ORCID</a> &nbsp &nbsp &nbsp &nbsp &nbsp
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/Jiang.png"><img style="width:100%;max-width:100%; "
                                                           alt="jiang liu profile photo"
                                                           src="images/Jiang.png" class="hoverZoomLink"></a>
		    </td>
                </tr>
                </tbody>

	    


            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding: 20px;width:100%;vertical-align:middle">
                        <heading>News & Activities</heading>
                        <hr>
                    </td>
                </tr>
                </tbody>
            </table>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="100%" valign="center">
			<span>&#8226;</span>  <span class="label label-info">12/2024</span>  Our work is submitted to ICME. ðŸ‘€ <br> 
			<span>&#8226;</span>  <span class="label label-info">12/2024</span>  Our work is submitted to IEEE TIM. ðŸ‘€<br> 
			<span>&#8226;</span>  <span class="label label-info">12/2024</span>  Our work is submitted to IEEE TCSVT. ðŸ‘€<br> 
			<span>&#8226;</span>  <span class="label label-info">11/2024</span>  One paper is accepted by Elsevier ESWA! ðŸŽ‰ðŸŽ‰<br> 
			<span>&#8226;</span>  <span class="label label-info">10/2024</span>  Give a presentation at our Visual Computing Research Seminar. ðŸŽ¤<br> 
			<span>&#8226;</span>  <span class="label label-info">07/2024</span>  One patent is issued! ðŸŽ‰ðŸŽ‰<br> 
			<span>&#8226;</span>  <span class="label label-info">05/2024</span>  One paper is accepted by IEEE TCSVT! ðŸŽ‰ðŸŽ‰<br> 
				<br> 
			
			
                    </td>
                </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Research</heading>
                        <hr>
			<p style="margin-top: 10px; font-weight: normal; font-size: 14px;">(<span style="font-size: 0.8em; vertical-align: super;">#</span>   denotes corresponding author)</p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>


<tr onmouseout="wvf_start()" onmouseover="wvf_stop()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='wvf_image'><img src='images/review.jpg' width="160" height="160"></div>
                            <img src='images/review.jpg' width="160" height="160">
                        </div>
                        <script type="text/javascript">
                            function wvf_start() {
                                document.getElementById('wvf_image').style.opacity = "1";
                            }

                            function wvf_stop() {
                                document.getElementById('wvf_image').style.opacity = "0";
                            }

                            wvf_start()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://www.sciencedirect.com/science/article/pii/S0957417424025090">
                            <papertitle>Vision-based human action quality assessment: A systematic review</papertitle>
                        </a>
                        <br>
                        <strong>Jiang Liu</strong>, Huasheng Wang, Katarzyna Stawarz, Shiyin Li, Yao Fu, Hantao Liu
                        <br>
                        <em>Expert Systems with Applications (ESWA)</em>, 2024 &nbsp 
			<br>
			Impact Fator: 7.5
                        <br>
                        <p></p>
                        <p><b>Highlight:</b><br>
                            <tldr>
<span>&#8226;</span> The first systematic literature review to investigate up-to-date research in vision-based AQA<br> <span>&#8226;</span> This study offers a detailed examination of 96 papers, including their applications, datasets, data modalities, methods, and evaluation metrics.<br> <span>&#8226;</span> This review identifies current challenges in existing research, providing valuable insights and recommendations for future studies. These suggestions are intended to inspire the development of new methods and applications within the AQA field.
</tldr>
                        </p>
                    </td>
                </tr>
                



		<tr onmouseout="wvf_start()" onmouseover="wvf_stop()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='wvf_image'><img src='images/aga.png' width="160" height="160"></div>
                            <img src='images/aga.png' width="160" height="160">
                        </div>
                        <script type="text/javascript">
                            function wvf_start() {
                                document.getElementById('wvf_image').style.opacity = "1";
                            }

                            function wvf_stop() {
                                document.getElementById('wvf_image').style.opacity = "0";
                            }

                            wvf_start()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://ieeexplore.ieee.org/abstract/document/10539107">
                            <papertitle>Blind Image Quality Assessment via Adaptive Graph Attention</papertitle>
                        </a>
                        <br>
                        Huasheng Wang, <strong>Jiang Liu<span style="font-size: 0.8em; vertical-align: super;">#</span></strong>, Hongchen Tan, Jianxun Lou, Xiaochang Liu, Wei Zhou, Hantao Liu
                        <br>
                        <em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</em>, 2024 &nbsp
			<br>
			Impact Fator: 8.3
                        <br>
                        <p></p>
                        <p><b>Highlight:</b><br>
                            <tldr>
<span>&#8226;</span> We devise a novel Adaptive Graph Attention module for deep learning-based IQA.<br> <span>&#8226;</span> We propose a Patch-wise-based Hierarchical Perceptual regression module to combine MSE and deep ordinal (DO) regression for inferring scores from different patches at various depths of the network.<br> <span>&#8226;</span> We show the substantial superiority of the proposed BIQA model over existing alternative models, through extensive experiments on many benchmark datasets.
</tldr>
                        </p>
                    </td>
                </tr>
                

                <tr onmouseout="wvf_start()" onmouseover="wvf_stop()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='wvf_image'><img src='images/incorporation.jpg' width="160" height="160"></div>
                            <img src='images/incorporation.jpg' width="160" height="160">
                        </div>
                        <script type="text/javascript">
                            function wvf_start() {
                                document.getElementById('wvf_image').style.opacity = "1";
                            }

                            function wvf_stop() {
                                document.getElementById('wvf_image').style.opacity = "0";
                            }

                            wvf_start()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://www.sciencedirect.com/science/article/pii/S0959652620358261?via=ihub">
                            <papertitle>Incorporating slam and mobile sensing for indoor co2 monitoring and source position 							estimation</papertitle>
                        </a>
                        <br>
                        Yuan Yang, <strong>Jiang Liu</strong>, Wei Wang, Yu Cao, Heng Li
                        <br>
                        <em>Journal of Cleaner Production (JCP)</em>, 2021 &nbsp
			<br>
			Impact Fator: 9.8
                        <br>
                        <p></p>
                        <p><b>Highlight:</b><br>
                            <tldr>
<span>&#8226;</span> Distinguish from stationary monitoring, this study provides a set of schemes that enable a mobile robot with real-time position tracking and IAQ online sensing.<br> <span>&#8226;</span> Mobile sensing provides a self-controlled, high resolution, wireless and trackable strategy with agile adaptions to the dynamic indoor environment.<br> <span>&#8226;</span> Automatically detecting indoor pollutant sources and locating where they are, can be beneficial for environment analysis, building security and energy control.
</tldr>
                        </p>
                    </td>
                </tr>
                    
                    
                
                
                </tbody>
            </table>
            <br>
            <br>
            <br>


            <!--            reviewer section-->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td>
                        <heading>Professional Activities</heading>
                        <hr>
                    </td>
                </tr>
                </tbody>
            </table>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="100%" valign="center">

                        <span>&#8226;</span> Reviewer of IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) <br> 
			<span>&#8226;</span> Reviewer of IEEE Transactions on Neural Networks and Learning Systems (TNNLS) <br> 
			<span>&#8226;</span> Reviewer of Neurocomputing <br> 
			<span>&#8226;</span> Reviewer of IEEE Signal Processing Letters <br> <br> 

			<span>&#8226;</span> Research Assistant (2023.05 - 2023.07) for <a href="https://scholar.google.co.uk/citations?user=V5E7JXsAAAAJ&hl=en">Prof. Paul Rosin </a> in building Cardiff Conversation Database <br> 
			<span>&#8226;</span> Teacher Assistant (2023.10 - 2023.12) for Dr.Jianhua Shao in 23/24-CM2102 Database Systems <br> 
                    </td>
                </tr>
                </tbody>
            </table>
            <br>
            <br>
            <br>

            <!--            supervision section-->
            

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td>
                        <heading>Patents</heading>
                        <hr>
                    </td>
                </tr>
                </tbody>
            </table>
            <table width="100%" align="center" border="0" cellpadding="20">
                <tbody>
                <tr>

                    <td width="100%" valign="center">
			<span>&#8226;</span> <strong> Liu Jiang </strong>. 2024. The indoor personnel localization method based on feature extraction adaptive neural network and CO2. CN1124847348. Filed March 30, 2021, and issued July 23,2024.
                        <br>
                        <span>&#8226;</span> <strong> Liu Jiang </strong>. 2021. Indoor multi-source environment health index monitoring 			and evaluating method based on mobile robot. CN112113603. Filed December 22, 2020, and issued July 23,2021.
                        <br>
                        <span>&#8226;</span> <strong> Liu Jiang </strong>. 2021. Indoor positioning fingerprint database comprehensive 				generation method based on WiFi multipath similarity. CN111565452. Filed August 21, 2020, and issued January 				12,2021.
                    </td>
                </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px; text-align:right;">
                        <br>
			<a href="https://clustrmaps.com/site/1c3p5" title="Visit tracker"><img src="https://clustrmaps.com/map_v2.png?cl=ffffff&w=400&t=tt&d=CfTmd-lMWC2N2z_I2Dmu0lxRBJiZkN49UuuDXM1BboM" /></a>
                        <p style="text-align:right;font-size:small;">
                            <credits>based on a template by <a href="https://jonbarron.info/"><font face="lato"
                                                                                                    size="1">Jonathan
                                Barron</font></a></credits>
                        </p>

                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</table>

</body>

</html>
